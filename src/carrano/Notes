Upper Bound - Worst Case - Big Oh
Lower Bound - Best Case - Big Omega
Upper and Lower - Big Theta

Stack - Abstract Data Structure

Sorting:

1.  Bubble Sort
    Repeatedly compares adjacent elements of array.  Sorts adjacent elements.
After each pass, the "rightmost" element in the array is sorted.  Eg:

1 4 3 5 6 2 - Initial
1 3 4 5 2 6 - After First Pass
1 3 4 2 5 6 - After Second Pass
1 3 2 4 5 6 - After Third Pass
1 2 3 4 5 6 - After Fourth Pass
1 2 3 4 5 6 - After Fifth Pass
fin

Time Complexity:
Best Case: O(n^2)
Worst Case: O(n^2)
Average Case: O(n^2)

Space Complexity:
O(1) Auxiliary


2.  Selection Sort
    Selects the smallest element and moves it to the beginning of the array.

8 3 2 5 1 4 - Initial
1 3 2 5 8 4 - After First Pass
1 2 3 5 8 4 - After Second Pass
1 2 3 5 8 4 - After Third Pass
1 2 3 4 8 5 - After Fourth Pass
1 2 3 4 5 8 - After Fifth Pass
fin

Time Complexity:
Best Case: O(n^2)
Worst Case: O(n^2)
Average Case: O(n^2)
O(n^2) comparisons, but only O(n) swaps

Space Complexity:
O(1) Auxiliary

3.  Insertion Sort
    Iterates through an array, sorting all elements to the left of the index.

8 3 2 5 1 4 - Initial
3 8 2 5 1 4 - At index 0
2 3 8 5 1 4 - At Index 1
2 3 8 5 1 4 - at Index 2
2 3 5 8 1 4 - at Index 3
1 2 3 5 8 4 - at Index 4
1 2 3 4 5 8 - at Index 5
fin

4.  Shell Sort

# Sort an array a[0...n-1].
gaps = [701, 301, 132, 57, 23, 10, 4, 1]

# Start with the largest gap and work down to a gap of 1
foreach (gap in gaps)
{
    # Do a gapped insertion sort for this gap size.
    # The first gap elements a[0..gap-1] are already in gapped order
    # keep adding one more element until the entire array is gap sorted
    for (i = gap; i < n; i += 1)
    {
        # add a[i] to the elements that have been gap sorted
        # save a[i] in temp and make a hole at position i
        temp = a[i]
        # shift earlier gap-sorted elements up until the correct location for a[i] is found
        for (j = i; j >= gap and a[j - gap] > temp; j -= gap)
        {
            a[j] = a[j - gap]
        }
        # put temp (the original a[i]) in its correct location
        a[j] = temp
    }
}

Worst case performance 	O(n2)
Best case performance 	O(n log2 n)
Average case performance 	depends on gap sequence
Worst case space complexity 	О(n) total, O(1) auxiliary

Merge Sort

Class 	Sorting algorithm
Data structure 	Array
Worst case performance 	O(n log n)
Best case performance 	

O(n log n) typical,
O(n) natural variant
Average case performance 	O(n log n)
Worst case space complexity 	О(n) total, O(n) auxiliary

Quick Sort

Divides an array into two pieces
    Chooses one entry in the array called the pivot.
    Partitions the array about the pivot

Best case performance 	O(n log n) (simple partition)
or O(n) (three-way partition and equal keys)
Average case performance 	O(n log n)
Worst case space complexity 	O(n) auxiliary (naive)
O(log n) auxiliary (Sedgewick 1978)

Quicksort is a divide and conquer algorithm. Quicksort first divides a large array into two smaller sub-arrays: the low elements and the high elements. Quicksort can then recursively sort the sub-arrays.

The steps are:

    Pick an element, called a pivot, from the array.
    Reorder the array so that all elements with values less than the pivot come before the pivot, while all elements with values greater than the pivot come after it (equal values can go either way). After this partitioning, the pivot is in its final position. This is called the partition operation.
    Recursively apply the above steps to the sub-array of elements with smaller values and separately to the sub-array of elements with greater values.

The base case of the recursion is arrays of size zero or one, which never need to be sorted. A quicksort that sorts elements lo through hi (inclusive) of an array A can be expressed as function quicksort(A, lo, hi). Sorting the entire array is accomplished by calling quicksort(A, 1, length(A)).

Lists

    Array -
        Insertion Operation complexity is very high.
        Resize Operation complexity is very high.
        Uses fixed size of memory
        Can use binary (logarithmic) search

    Linked Node List -
        Insertion Operation in O(n) time
        Resize Operation not required 
        Uses only required memory
        Can only use linear search

Trees

    Binary Tree
        Each node has at most two descendents
        Full Tree:
            Each tree in a level have either 2 descendents or zero descendents
            Has 2^n - 1 nodes where n is the number of levels
        Complete Tree
            Each Tree either has 2 descendents or no descendents

    Traversal of a Binary Tree
        Preorder Traversal
            Start at root.  Goto left subtrees first.
        Inorder Traversal
        Postorder Traversal
        Level-order Traversal

Hashing

    Hash : A to N is a function
    Horner's Algorithm - Look it up

Dictionary
    A collection of key value pairs