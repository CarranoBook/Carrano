Upper Bound - Worst Case - Big Oh
Lower Bound - Best Case - Big Omega
Upper and Lower - Big Theta

Stack - Abstract Data Structure

Sorting:

1.  Bubble Sort
    Repeatedly compares adjacent elements of array.  Sorts adjacent elements.
After each pass, the "rightmost" element in the array is sorted.  Eg:

1 4 3 5 6 2 - Initial
1 3 4 5 2 6 - After First Pass
1 3 4 2 5 6 - After Second Pass
1 3 2 4 5 6 - After Third Pass
1 2 3 4 5 6 - After Fourth Pass
1 2 3 4 5 6 - After Fifth Pass
fin

Time Complexity:
Best Case: O(n^2)
Worst Case: O(n^2)
Average Case: O(n^2)

Space Complexity:
O(1) Auxiliary


2.  Selection Sort
    Selects the smallest element and moves it to the beginning of the array.

8 3 2 5 1 4 - Initial
1 3 2 5 8 4 - After First Pass
1 2 3 5 8 4 - After Second Pass
1 2 3 5 8 4 - After Third Pass
1 2 3 4 8 5 - After Fourth Pass
1 2 3 4 5 8 - After Fifth Pass
fin

Time Complexity:
Best Case: O(n^2)
Worst Case: O(n^2)
Average Case: O(n^2)
O(n^2) comparisons, but only O(n) swaps

Space Complexity:
O(1) Auxiliary

3.  Insertion Sort
    Iterates through an array, sorting all elements to the left of the index.

8 3 2 5 1 4 - Initial
3 8 2 5 1 4 - At index 0
2 3 8 5 1 4 - At Index 1
2 3 8 5 1 4 - at Index 2
2 3 5 8 1 4 - at Index 3
1 2 3 5 8 4 - at Index 4
1 2 3 4 5 8 - at Index 5
fin

4.  Shell Sort

# Sort an array a[0...n-1].
gaps = [701, 301, 132, 57, 23, 10, 4, 1]

# Start with the largest gap and work down to a gap of 1
foreach (gap in gaps)
{
    # Do a gapped insertion sort for this gap size.
    # The first gap elements a[0..gap-1] are already in gapped order
    # keep adding one more element until the entire array is gap sorted
    for (i = gap; i < n; i += 1)
    {
        # add a[i] to the elements that have been gap sorted
        # save a[i] in temp and make a hole at position i
        temp = a[i]
        # shift earlier gap-sorted elements up until the correct location for a[i] is found
        for (j = i; j >= gap and a[j - gap] > temp; j -= gap)
        {
            a[j] = a[j - gap]
        }
        # put temp (the original a[i]) in its correct location
        a[j] = temp
    }
}

Worst case performance 	O(n2)
Best case performance 	O(n log2 n)
Average case performance 	depends on gap sequence
Worst case space complexity 	О(n) total, O(1) auxiliary

Merge Sort

Class 	Sorting algorithm
Data structure 	Array
Worst case performance 	O(n log n)
Best case performance 	

O(n log n) typical,
O(n) natural variant
Average case performance 	O(n log n)
Worst case space complexity 	О(n) total, O(n) auxiliary

Quick Sort

Divides an array into two pieces
    Chooses one entry in the array called the pivot.
    Partitions the array about the pivot

Best case performance 	O(n log n) (simple partition)
or O(n) (three-way partition and equal keys)
Average case performance 	O(n log n)
Worst case space complexity 	O(n) auxiliary (naive)
O(log n) auxiliary (Sedgewick 1978)

Quicksort is a divide and conquer algorithm. Quicksort first divides a large array into two smaller sub-arrays: the low elements and the high elements. Quicksort can then recursively sort the sub-arrays.

The steps are:

    Pick an element, called a pivot, from the array.
    Reorder the array so that all elements with values less than the pivot come before the pivot, while all elements with values greater than the pivot come after it (equal values can go either way). After this partitioning, the pivot is in its final position. This is called the partition operation.
    Recursively apply the above steps to the sub-array of elements with smaller values and separately to the sub-array of elements with greater values.

The base case of the recursion is arrays of size zero or one, which never need to be sorted. A quicksort that sorts elements lo through hi (inclusive) of an array A can be expressed as function quicksort(A, lo, hi). Sorting the entire array is accomplished by calling quicksort(A, 1, length(A)).

Lists

    Array -
        Insertion Operation complexity is very high.
        Resize Operation complexity is very high.
        Uses fixed size of memory
        Can use binary (logarithmic) search

    Linked Node List -
        Insertion Operation in O(n) time
        Resize Operation not required 
        Uses only required memory
        Can only use linear search

Trees

    
    Root – The top node in a tree.
    Parent – The converse notion of a child.
    Siblings – Nodes with the same parent.
    Descendant – a node reachable by repeated proceeding from parent to child.
    Ancestor – a node reachable by repeated proceeding from child to parent.
    Leaf – a node with no children.
    Internal node – a node with at least one child.
    External node – a node with no children.
    Degree – number of sub trees of a node.
    Edge – connection between one node to another.
    Path – a sequence of nodes and edges connecting a node with a descendant.
    Level – The level of a node is defined by 1 + (the number of connections between the node and the root).
    Height of tree –The height of a tree is the number of edges on the longest downward path between the root and a leaf.
    Height of node –The height of a node is the number of edges on the longest downward path between that node and a leaf.
    Depth –The depth of a node is the number of edges from the node to the tree's root node.
    Forest – A forest is a set of n ≥ 0 disjoint trees.


    Binary Tree
        
        A rooted binary tree has a root node and every node has at most two children.
            A full binary tree (sometimes referred to as a proper[15] or plane binary 
            tree)[16][17] is a tree in which every node in the tree has either 0 or 2 
            children.

        A perfect binary tree is a binary tree in which all interior nodes have 
            two children and all leaves have the same depth or same level.[18] 
            (This is ambiguously also called a complete or full binary tree.[citation needed]) 
            An example of a perfect binary tree is the ancestry chart of a person 
            to a given depth, as each person has exactly two biological parents 
            (one mother and one father).
       
        In a complete binary tree every level, except possibly the last, is 
            completely filled, and all nodes in the last level are as far left 
            as possible. It can have between 1 and 2h nodes at the last level 
            h.[19] An alternative definition is a perfect tree whose rightmost 
            leaves (perhaps all) have been removed. A binary tree is called an 
            almost complete binary tree or nearly complete binary tree if the 
            last level is not completely filled.[clarification needed] A 
            complete binary tree is used as a specialized data structure called 
            a binary heap.[19]

        In the infinite complete binary tree, every node has two children 
            (and so the set of levels is countably infinite). The set of all 
            nodes is countably infinite, but the set of all infinite paths 
            from the root is uncountable, having the cardinality of the 
            continuum. These paths correspond by an order-preserving bijection 
            to the points of the Cantor set, or (using the example of a 
            Stern–Brocot tree) to the set of positive irrational numbers.
        
        A balanced binary tree has the minimum possible maximum height 
            (a.k.a. depth) for the leaf nodes, because for any given number of 
            leaf nodes the leaf nodes are placed at the greatest height 
            possible.[clarification needed]
        
        A degenerate (or pathological) tree is where each parent node has only 
            one associated child node.[citation needed] This means that 
            performance-wise[clarification needed], the tree will behave like a 
            linked list data structure.


    Traversal of a Binary Tree
        Preorder Traversal
            Start at root.  Goto left subtrees first.
            When a leaf is found, go up to parent node.
            If parent has a right node, go to right node.  
                Else, go to next parent.

            "Keep left shoulder touching the edges of the tree at all times"
        Inorder Traversal
            Traverse left subtrees by recursively calling the in-order method
            Traverse right subtrees by recursively calling the in-order method.

            Turns a Binary Search Tree into a sorted list

        Postorder Traversal
            
        Level-order Traversal

Hashing

    Hash : A to N is a function
    Horner's Algorithm - Look it up

Dictionary
    A collection of key value pairs



1) What data types need to be stored
2) Cost of operation
3) Memory usage
4) Ease of implementation